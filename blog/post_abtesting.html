<!DOCTYPE html>
<html>
<head>
    <!--  Favicon  -->
    <link rel="apple-touch-icon" sizes="180x180" href="../favicons/apple-touch-icon.png">
    <link rel="manifest" href="../favicons/site.webmanifest">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicons/favicon-16x16.png">
    <link rel="shortcut icon" href="../favicons/favicon.ico">

    <!-- Meta Info -->
    <title>Francesco Casalegno - Personal Website</title>
    <meta charset="UTF-8">
    <meta name="description" content="Francesco Casalegno's personal website">
    <meta name="keywords" content="personal website, blog, data science, machine learning">
    <meta name="author" content="Francesco Casalegno">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Open Graph Meta -->
    <meta property="og:title" content="A/B Testing — A complete guide to statistical testing">
    <meta property="og:description"
          content="With the right statistical analysis, A/B tests can tremendously improve business strategies.">
    <meta property="og:image" content="https://francescocasalegno.github.io/images/home-bg.jpg">
    <meta property="og:url" content="http://francescocasalegno.github.io/blog/post_abtesting.html">
    <meta property="og:site_name" content="Francesco Casalegno's personal website">
    <meta name="twitter:card" content="summary_large_image">

    <!-- Style -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat&display=swap">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto&display=swap">
    <link rel="stylesheet" href="../css/style.css">

    <!-- Scripts -->
    <script src="https://kit.fontawesome.com/0bff17aed7.js" crossorigin="anonymous"></script>


    <link rel="stylesheet"
          href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/darcula.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.3.2/languages/python.min.js"
            integrity="sha512-5IwlvN3ATowZMxsKB/BwpqzQuUA/6PBVTrf/6cZ452Sl7TGWqqd0I0r8M9SHmF5C6hh0gCOLRSyDwQEeyEQ3Dw=="
            crossorigin="anonymous"></script>

    <script>hljs.initHighlightingOnLoad();</script>

</head>
<body>
<!-- Navigation -->
<nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="container">
        <a class="navbar-brand" href="../index.html">Francesco Casalegno</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse"
                data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false"
                aria-label="Toggle navigation">
            Menu
            <i class="fas fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                    <a class="nav-link" href="../index.html">About</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link nav-currentpage" href="../blog.html">Blog</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="../resume.html">Resume</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="../contact.html">Contact</a>
                </li>
            </ul>
        </div>
    </div>
</nav>

<!-- Page Header -->
<header class="masthead" style="background-image: url('../images/home-bg.jpg')">
    <div class="overlay"></div>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-md-10 mx-auto">
                <div class="site-heading">
                    <h1>A/B Testing</h1>
                    <h2>A complete guide to statistical testing</h2>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Main Content -->
<div class="container">
    <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
            <h1>What is A/B testing? <a class="headerlink" id="he1" href="#he1"
                                        title="Permalink to this headline"><i
                    class="fas fa-link"></i></a></h1>
            <p>
                <strong>A/B testing</strong>
                is one of the most popular kind of controlled experiment performed
                by companies to help designing their web marketing strategies.
                It allows decision makers to choose the design for a website by looking
                at the analytics results obtained with two possible designs A and B.
            </p>
            <p>
                More precisely, A/B testing consists in creating two alternative
                designs A and B of the same website, and then randomly serving
                visitors with either A or B.
                We can assume that A is the original (control) design while B
                is a propose variation.
                Then, by looking at web analytics,
                we want to apply statistical methods to determine whether
                one of the two designs improves the efficacy of the webpage.
            </p>
            <p>
                Different kinds of metrics can be used to measure a website efficacy.
                First, we have <strong>binomial (or discrete) metrics</strong>,
                where only the two values 0 and 1 (or False and True) are possible.
            </p>
            <ul>
                <li><a href="https://en.wikipedia.org/wiki/Click-through_rate">Click-through rate</a> — if a
                    user is shown an advertisement, do they click on it?
                </li>
                <li><a href="https://en.wikipedia.org/wiki/Conversion_rate_optimization">Conversion rate</a> — if a
                    user is shown an advertisement, do they convert into customers?
                </li>
                <li><a href="https://en.wikipedia.org/wiki/Bounce_rate">Bounce rate</a> — if a
                    user is visits a website, is the next webpage they visit on the same website?
                </li>
            </ul>
            <div style="text-align: center;">
                <img src="../images/abtesting/ab_discrete.png" width="100%" alt="Discrete metrics: click-through rate.">
            </div>
            </p>
            Second, we have <strong>non-binomial (or continuous) metrics</strong>,
            where the possible values may take continuous values are not
            limited to two discrete states.
            </p>
            <ul>
                <li><a href="https://en.wikipedia.org/wiki/Average_revenue_per_user">Average revenue per user</a> —
                    how much revenue does a user generate in a month?
                </li>
                <li><a href="https://en.wikipedia.org/wiki/Session_(web_analytics)">Average session duration</a> —
                    for how long does a user spend on a website in a session?
                </li>
                <li><a href="https://www.optimizely.com/optimization-glossary/average-order-value/">Average order
                    value</a> — what is the total value of the order of a user?
                </li>
            </ul>
            <div style="text-align: center;">
                <img src="../images/abtesting/ab_continuous.png" width="100%"
                     alt="Continuous metrics: average order value.">
            </div>
            <p>

            </p>
            <h1>Statistical significance <a class="headerlink" id="he2" href="#he2"
                                            title="Permalink to this headline"><i
                    class="fas fa-link"></i></a>
            </h1>
            <p>
                Once we have collected some data from the activity of the users
                of our website, we can start comparing the efficacy of the two
                designs A and B.
                A simple comparison of the mean values obtained for the two samples
                is not very meaningful, as what we have to compute is also the
                <strong>statistical significance</strong>, i.e. determine how
                likely it is that the observed discrepancy between the two samples
                originates from chance.
            </p>
            <p>
                The <strong>null hypothesis H<sub>0</sub></strong> of our test is
                that the two designs A and B have the same efficacy, i.e. that they
                produce an equivalent click-through rate, or average revenue per user, etc.
                The statistical significance is then measured by the <strong>p-value</strong>,
                i.e. the probability of observing a discrepancy between our samples
                at least as strong as the one that we actually observed.
            </p>
            <div style="text-align: center;">
                <img src="../images/abtesting/p_val.png" width="100%"
                     alt="P-value.">
            </div>
            <p>
                Now, some care has to be applied to properly choose
                the <strong>alternative hypothesis H<sub>a</sub></strong>. This
                choice corresponds to choosing between
                <a href="https://en.wikipedia.org/wiki/One-_and_two-tailed_tests">
                    one- and two- tailed tests
                </a>.
            </p>
            <p>
                A <strong>two-tailed test</strong> is preferable in our case, since
                we have no reason to know a priori whether the discrepancy between
                the results of A and B will be in favor of A or B. For this reason,
                we will have to compute the p-value as the area under the the two tails of
                the probability density function <strong>p(x)</strong> of a chosen test statistic on all
                <strong>x'</strong> s.t. <strong>p(x') <= p(our observation)</strong>.
            </p>
            <div style="text-align: center;">
                <img src="../images/abtesting/tails.png" width="100%"
                     alt="One- and two- tailed tests.">
            </div>
            <p>
                For A/B testing it is best to define <strong>H<sub>a</sub></strong>
                as the hypothesis that A and B have different efficacy, as we have
                no reason to make a priori assumptions on design A being better than B
                or vice versa.
            </p>
            <p>
                The computation of the p-value depends on the distribution of our
                data. So we will see first how to compute the significance of an A/B test
                with discrete data, and then how to do that if data are continuous.
            </p>
            <h1>Discrete metrics <a class="headerlink" id="he3" href="#he3"
                                    title="Permalink to this headline"><i
                    class="fas fa-link"></i></a>
            </h1>
            <p>
                Let's consider first discrete metrics, e.g. click-though rate. We
                randomly show visitors one of two possible designs of
                an advertisement, and based on how many of them click on it we
                need to determine whether our data significantly contradict the
                hypothesis that the two designs are equivalently efficient.
            </p>
            <p>
                In the following example, let's say that the actual observations were the following:
                15 visitors saw the advertisement A and 7 of them clicked on it, while
                19 visitors saw the advertisement B and 15 of them clicked on it. At a first sight,
                it looks like version B was more effective, but how statistically significant is this
                discrepancy?
            </p>
            <div style="text-align: center;">
                <img src="../images/abtesting/fisher_cont_tables_1.png" width="70%"
                     alt="Click-through ratios: contingency table.">
            </div>
            <p></p>
            <h2>Fisher's exact test <a class="headerlink" id="he3_1" href="#he3_1"
                                       title="Permalink to this headline"><i
                    class="fas fa-link"></i></a>
            </h2>
            <p>
                Since we have a 2x2 <a
                    href="https://en.wikipedia.org/wiki/Contingency_table">contingency table
            </a> we can use <a href="https://en.wikipedia.org/wiki/Fisher%27s_exact_test">
                Fisher's exact test</a> to compute an exact p-value and test our hypothesis.
                To understand how this test works, let us start by noticing that
                if we fix the margins of the tables (i.e. the four sums of each row and column),
                then only few different outcomes are possible.
            </p>
            <div style="text-align: center;">
                <img src="../images/abtesting/fisher_cont_tables_2.png" width="70%"
                     alt="Click-through ratios: possible outcomes">
            </div>
            <p>
                Now, the key observation is that the probability of each of these
                possible outcomes is given by the <a
                    href="https://en.wikipedia.org/wiki/Hypergeometric_distribution">hypergeometric
                distribution
            </a>.
            </p>
            <div style="text-align: center;">
                <img src="../images/abtesting/hypergeom.png" width="100%"
                     alt="Click-through ratios: hypergeometric distribution">
            </div>
            <p>
                By using this formula we can compute that, if A and B had equivalent efficacy, then
            </p>
            <ul>
                <li>the probability of seeing our actual observations is ~4.5%</li>
                <li>the probability of seeing even more unlikely observations in favor if B is
                    ~1% (left tail)
                </li>
                <li>the probability of seeing observations even more unlikely observations in favor if A
                    is ~2% (right tail)
                </li>
            </ul>
            <p>So, using Fisher's exact test, we obtain p-value of ~7.5%.</p>
            <div style="text-align: center;">
                <img src="../images/abtesting/fisher_hypergeom_distr.png" width="60%"
                     alt="Click-through ratios: tails and p-value">
            </div>
            <p></p>
            <h2>Pearson's chi-squared test <a class="headerlink" id="he3_2" href="#he3_2"
                                              title="Permalink to this headline"><i
                    class="fas fa-link"></i></a>
            </h2>
            <p>
                Fisher's exact test has the important advantage of computing exact p-values.
                But if we have a large sample size, it may be computationally
                inefficient. In this case, we can use
                <a href="https://en.wikipedia.org/wiki/Pearson%27s_chi-square_test">
                    Pearson's chi-squared test</a> to compute an approximate p-value.
            </p>
            <p>
                Let us call <strong>O<sub>ij</sub></strong> the observed value of
                the contingency table at row <strong>i</strong> and column <strong>j</strong>.
                Under the null hypothesis of independence of rows and columns, i.e.
                assuming that seeing the design version A or B has no impact on the
                likelihood of clicking on it,
                we can easily compute corresponding expected values <strong>E<sub>ij</sub></strong>.
                Moreover, if the observations are normally distributed, then the χ<sup>2</sup>
                statistic follows exactly a <a href="https://en.wikipedia.org/wiki/Chi-square_distribution">
                chi-square distribution
            </a> with 1 degree of freedom.
            </p>
            <div style="text-align: center;">
                <img src="../images/abtesting/chisq.png" width="100%"
                     alt="Click-through ratios: tails and p-value">
            </div>
            <p></p>
            <p>
                In fact, the test can also be used with non-normal observations, if the
                sample size is large enough (thanks to the <a
                    href="https://en.wikipedia.org/wiki/Central_limit_theorem">central limit theorem</a>).

                But in our example the sample size is relatively small and
                the p-value of Pearson's chi-square is ~5.1%, which is quite
                different from the one we computed before with Fisher's exact
                test.
            </p>
            <h1>Continuous metrics <a class="headerlink" id="he4" href="#he4"
                                      title="Permalink to this headline"><i
                    class="fas fa-link"></i></a>
            </h1>
            <p>
                Let's now consider the case of a continuous metrics, e.g. average revenue per user. We
                randomly show visitors of our website one of two possible layouts of products for sale,
                and based on how much revenue each user generated in a month we
                want to determine whether our data significantly contradict the
                hypothesis that the two website layouts are equivalently efficient.
            </p>
            <p>
                To make a concrete example, let's consider the following case.
            </p>
            <ul>
                <li> <strong>n<sub>X</sub>=17</strong> users saw the layout A, and then made the following purchases:
                200$, 150$, 250$, 350$, 150$, 150$, 350$, 250$, 150$, 250$, 150$, 150$, 200$, 0$, 0$, 100$, 50$.
                We denote the i-th purchase by <strong>X<sub>i</sub></strong>.</li>
                <li> <strong>n<sub>X</sub>=14</strong> users saw the layout B, and then made the following purchases:
                300$, 150$, 150$, 400$, 250$, 250$, 150$, 200$, 250$, 150$, 300$, 200$, 250$, 200$.
                We denote the i-th purchase by <strong>Y<sub>i</sub></strong>.
                </li>
            </ul>
            <p>
                If we plot these values, at a first sight,
                it looks like version B was more effective. But how statistically significant is this
                discrepancy?
            </p>
            <div style="text-align: center;">
                <img src="../images/abtesting/cont_sample.png" width="60%"
                     alt="Average revenue per user: samples distribution">
            </div>
            <p></p>
            <h2>Z-test <a class="headerlink" id="he4_1" href="#he4_1"
                          title="Permalink to this headline"><i
                    class="fas fa-link"></i></a>
            </h2>
            <p>
                The <a href="https://en.wikipedia.org/wiki/Z-test">Z-test</a> can be applied
                under the following assumptions.
            </p>
            <ul>
                <li>The observations are normally distributed (or the sample size is large).</li>
                <li>The sampling distributions have known variance <strong>σ<sub>X</sub></strong> and
                <strong>σ<sub>Y</sub></strong>.</li>
            </ul>
            <p>
                Under the above assumptions, the Z-test relies on the observation that
                the following <strong>Z statistic</strong>  has a standard normal distribution.
            </p>
            <p>
                Unfortunately in most real applications the standard deviations are
                unknown and must be estimated, so a t-test is preferable, as we will see later.
                 Anyway, if in our case we are told that
                <strong>σ<sub>X</sub>=100</strong> and <strong>σ<sub>X</sub>=90</strong>,
                then we obtain <strong>z=-1.697</strong>, which corresponds to a <strong>p<sub>val</sub>=9%</strong>.
            </p>
            <p></p>
            <h2>Student's t-test <a class="headerlink" id="he4_2" href="#he4_2"
                                    title="Permalink to this headline"><i
                    class="fas fa-link"></i></a>
            </h2>
            <p>
                In most cases, the variances of the sampling distributions are unknown,
                so that we need to estimate them.
                <a href="https://en.wikipedia.org/wiki/Student%27s_t-test">Student's t-test</a> can
                then be applied  under the following assumptions.
            </p>
            <ul>
                <li>The observations are normally distributed (or the sample size is large).</li>
                <li>The sampling distributions have "similar" variances <strong>σ<sub>X</sub></strong> ≈
                <strong>σ<sub>Y</sub></strong>.</li>
            </ul>
            <p>
                Under the above assumptions, Student's t-test relies on the observation that
                the following <strong>t statistic</strong>  has a Student's t distribution.
            </p>
            <div style="text-align: center;">
                <img src="../images/abtesting/test_t_stud.png" width="100%"
                     alt="Student's t-test">
            </div>
            <p>
                Here <strong>S<sub>P</sub></strong> is the <a href="https://en.wikipedia.org/wiki/Pooled_variance">
                pooled variance
            </a> obtained from the sample variances <strong>S<sub>X</sub></strong> and <strong>S
                <sub>Y</sub></strong>, which are computed using the unbiased formula including <a
                    href="https://en.wikipedia.org/wiki/Bessel%27s_correction">Bessel's correction
            </a>).
            </p>
            <h2>Welch's t-test <a class="headerlink" id="he4_3" href="#he4_3"
                                  title="Permalink to this headline"><i
                    class="fas fa-link"></i></a>
            </h2>
            <p>
                In most cases Student's t test can be effectively applied with good results.
                However, it may rarely happen that its second assumption (similar variance
                of the sampling distributions) is violated. In that case, we
                cannot compute a pooled variance and rather than Student's t test
                we should use <a href="https://en.wikipedia.org/wiki/Welch%27s_t-test">Welch's t-test</a>.
            </p>
            <p>
                This test operates under the same assumptions of Student's t-test
                but removes the requirement on the similar variances. Then, we
                can use a slightly different <strong>t statistic</strong>, which
                also has a Student's t distribution, but with a different number
                of degrees of freedom <strong>ν</strong>.
            </p>
            <div style="text-align: center;">
                <img src="../images/abtesting/test_t_welch.png" width="100%"
                     alt="Student's t-test">
            </div>
            <p>
                The complex formula for <strong>ν</strong> comes from
                <a href="https://en.wikipedia.org/wiki/Welch%E2%80%93Satterthwaite_equation">
                    Welch–Satterthwaite equation
                </a>.
            </p>
            <h1>Continuous non-normal metrics <a class="headerlink" id="he5" href="#he5"
                                      title="Permalink to this headline"><i
                    class="fas fa-link"></i></a>
            </h1>
            <p>
                In the previous section on continuous metrics, we assumed
                that our observations came from normal distributions. But
                non-normal distributions are extremely common when dealing with
                per-user monthly revenues etc. There are several ways in which normality
                is often violated:
            </p>
            <ul>
                <li><a href="https://en.wikipedia.org/wiki/Zero-inflated_model">
                zero-inflated distributions
            </a> — most user don't buy anything at all, so lots of zero observations;</li>
                <li><a href="https://en.wikipedia.org/wiki/Multimodal_distribution">multimodal distributions</a> —
                a market segment tends purchases cheap products, while
                    another segment purchases more expensive products.
                </li>
            </ul>
            <div style="text-align: center;">
                <img src="../images/abtesting/non_normal_test_stat_distr.png" width="50%"
                     alt="Zero-inflated non-normal distribution">
            </div>
            <p>
                However, if we have enough samples, tests derived under normality
                assumptions like Z-test, Student's t-test, and Welch's t-test can
                still be applied for observations that signficantly deviate  from
                normality. Indeed, thanks to the <a
                    href="https://en.wikipedia.org/wiki/Central_limit_theorem">central limit theorem</a>,
                the distribution of the test statistics tends
                to normality as the sample size increases. In the zero-inflated
                and multimodal example we are considering, even a sample size
                of 40 produces a fairly normal distribution.
            </p>
            <div style="text-align: center;">
                <img src="../images/abtesting/non_norm_clt.png" width="100%"
                     alt="Zero-inflated non-normal distribution">
            </div>
            <p></p>
            <p>
                But if the sample size is still too small to assume normality,
                we can use an alternative, non-parametric approach such as the
                Mann-Whitney U test.
            </p>
            <h2>Mann–Whitney U test<a class="headerlink" id="he5_1" href="#he5_1"
                                  title="Permalink to this headline"><i
                    class="fas fa-link"></i></a>
            </h2>
            <p>
                This test makes the least assumptions about the nature of our observations,
                as it is fully nonparametric.
                The idea of <a href="https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test">Mann-Whitney U test</a>
                is to compute the following <strong>U statistic</strong>.
            </p>
            <div style="text-align: center;">
                <img src="../images/abtesting/test_u.png" width="100%"
                     alt="Mann–Whitney U test">
            </div>
            <p>
                The values of this test statistic are tabulated, as the distribution
                can be computed under the null hypothesis that, for
                random samples
                <strong>X</strong> and <strong>Y</strong> from the two populations,
                the probability <strong>P(X < Y)</strong> is the same as
                <strong>P(X > Y)</strong>.
            </p>
            <h1>Conclusions <a class="headerlink" id="he6" href="#he6"
                                  title="Permalink to this headline"><i
                    class="fas fa-link"></i></a>
            </h1>
            <p>
                We have seen that different kinds of metrics and observations
                require different kinds of statistical tests to measure the
                significance of the results obtained with A/B testing.
                The following diagram provides an overview of the methods
                presented in this article in the form of a decision tree.
            </p>
<!--            TODO: add computation of p-vals for all tests!-->
<!--            TODO: add link to notebook!-->
            <div style="text-align: center;">
                <img src="../images/abtesting/summary.png" width="100%"
                     alt="Summary of the statistical tests to be used for A/B testing">
            </div>
        </div>
    </div>
</div>

<hr>

<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-md-10 mx-auto">
                <ul class="list-inline text-center">
                    <li class="list-inline-item">
                        <a href="https://www.linkedin.com/in/francescocasalegno/">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-linkedin-in fa-stack-1x fa-inverse"></i>
                </span>
                        </a>
                    </li>
                    <li class="list-inline-item">
                        <a href="https://github.com/FrancescoCasalegno">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                </span>
                        </a>
                    </li>
                    <li class="list-inline-item">
                        <a href="https://medium.com/@francesco.casalegno">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-medium-m fa-stack-1x fa-inverse"></i>
                </span>
                        </a>
                    </li>
                </ul>
                <hr>
                <p class="copyright text-muted">Copyright &copy; Francesco Casalegno 2020</p>
            </div>
        </div>
    </div>
</footer>


<!-- jQuery -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

<!-- Bootstrap -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx"
        crossorigin="anonymous"></script>

<!-- Custom scripts for this template -->

</body>
</html>